{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\nimport keras\nimport tensorflow as tf\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, multiply, Permute, Concatenate, Add, Lambda\nfrom keras.activations import sigmoid\nfrom keras.layers import AveragePooling2D, Input, Flatten\n#from keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\n#from models import resnext, resnet_v1, resnet_v2, mobilenets, inception_v3, inception_resnet_v2, densenet\n#from utils import lr_schedule\nimport numpy as np\nimport os\nimport keras\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy.io import loadmat\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import confusion_matrix\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n%matplotlib inline\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:22.277527Z","iopub.execute_input":"2021-10-24T05:35:22.277844Z","iopub.status.idle":"2021-10-24T05:35:27.363440Z","shell.execute_reply.started":"2021-10-24T05:35:22.277752Z","shell.execute_reply":"2021-10-24T05:35:27.362684Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def lr_schedule(epoch):\n    \"\"\"Learning Rate Schedule\n\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n\n    # Arguments\n        epoch (int): The number of epochs\n\n    # Returns\n        lr (float32): learning rate\n    \"\"\"\n    lr = 1e-3\n    if epoch > 40:\n        lr *= 0.5e-3\n    elif epoch > 30:\n        lr *= 1e-3\n    elif epoch > 20:\n        lr *= 1e-2\n    elif epoch > 10:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:27.365019Z","iopub.execute_input":"2021-10-24T05:35:27.365274Z","iopub.status.idle":"2021-10-24T05:35:27.371674Z","shell.execute_reply.started":"2021-10-24T05:35:27.365241Z","shell.execute_reply":"2021-10-24T05:35:27.370883Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ndef resnet_layer(inputs,num_filters=16,kernel_size=3,strides=1,activation='relu',batch_normalization=True,conv_first=True):\n\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x\n\n\ndef cbam_block(cbam_feature, ratio=8):\n\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n\tAs described in https://arxiv.org/abs/1807.06521.\n\t\"\"\"\n\t\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature)\n\treturn cbam_feature\n\ndef channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t activation='relu',\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature.shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tactivation='sigmoid',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\t\n\tassert cbam_feature.shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:27.373031Z","iopub.execute_input":"2021-10-24T05:35:27.373505Z","iopub.status.idle":"2021-10-24T05:35:27.397062Z","shell.execute_reply.started":"2021-10-24T05:35:27.373462Z","shell.execute_reply":"2021-10-24T05:35:27.396357Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntrain_raw = loadmat('../input/svhndataset/train_32x32.mat')\ntest_raw = loadmat('../input/svhndataset/test_32x32.mat')\n# Load images and labels\n\ntrain_images = np.array(train_raw['X'])\ntest_images = np.array(test_raw['X'])\n\ntrain_labels = train_raw['y']\ntest_labels = test_raw['y']\n# Check the shape of the data\n\nprint(train_images.shape)\nprint(test_images.shape)\n# Fix the axes of the images\n\ntrain_images = np.moveaxis(train_images, -1, 0)\ntest_images = np.moveaxis(test_images, -1, 0)\n\nprint(train_images.shape)\nprint(test_images.shape)\n\n# Convert train and test images into 'float64' type\n\ntrain_images = train_images.astype('float64')\ntest_images = test_images.astype('float64')\n\n# Convert train and test labels into 'int64' type\n\ntrain_labels = train_labels.astype('int64')\ntest_labels = test_labels.astype('int64')\n\n# Normalize the images data\n\nprint('Min: {}, Max: {}'.format(train_images.min(), train_images.max()))\n\ntrain_images /= 255.0\ntest_images /= 255.0\n\n# One-hot encoding of train and test labels\n\nlb = LabelBinarizer()\ntrain_labels = lb.fit_transform(train_labels)\ntest_labels = lb.fit_transform(test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:27.399217Z","iopub.execute_input":"2021-10-24T05:35:27.399817Z","iopub.status.idle":"2021-10-24T05:35:35.319925Z","shell.execute_reply.started":"2021-10-24T05:35:27.399778Z","shell.execute_reply":"2021-10-24T05:35:35.319153Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels,test_size=0.15, random_state=22)\ndatagen = ImageDataGenerator(rotation_range=8,\n                             zoom_range=[0.95, 1.05],\n                             height_shift_range=0.10,\n                             shear_range=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:35.321364Z","iopub.execute_input":"2021-10-24T05:35:35.321618Z","iopub.status.idle":"2021-10-24T05:35:35.861620Z","shell.execute_reply.started":"2021-10-24T05:35:35.321585Z","shell.execute_reply":"2021-10-24T05:35:35.860815Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_filters = 16\nnum_res_blocks = 1\ninputs = Input(shape=(32, 32, 3))\nx = resnet_layer(inputs=inputs)\n# Instantiate the stack of residual units\nfor stack in range(3):\n    for res_block in range(num_res_blocks):\n        strides = 1\n        if stack > 0 and res_block == 0:  # first layer but not first stack\n            strides = 2  # downsample\n        y = resnet_layer(inputs=x,\n                         num_filters=num_filters,\n                         strides=strides)\n        y = resnet_layer(inputs=y,\n                         num_filters=num_filters,\n                         activation=None)\n        if stack > 0 and res_block == 0:  # first layer but not first stack\n            # linear projection residual shortcut connection to match\n            # changed dims\n            x = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=None,\n                             batch_normalization=False)\n        # attention_module\n        y = cbam_block(y)\n        x = keras.layers.add([x, y])\n        x = Activation('relu')(x)\n    num_filters *= 2\n\n# Add classifier on top.\n# v1 does not use BN after last shortcut connection-ReLU\nx = AveragePooling2D(pool_size=8)(x)\ny = Flatten()(x)\noutputs = Dense(10,\n                activation='softmax',\n                kernel_initializer='he_normal')(y)\n\n# Instantiate model.\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(lr=lr_schedule(0)),\n              metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:35.863804Z","iopub.execute_input":"2021-10-24T05:35:35.864100Z","iopub.status.idle":"2021-10-24T05:35:38.959545Z","shell.execute_reply.started":"2021-10-24T05:35:35.864063Z","shell.execute_reply":"2021-10-24T05:35:38.958621Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:35:38.960677Z","iopub.execute_input":"2021-10-24T05:35:38.961336Z","iopub.status.idle":"2021-10-24T05:35:40.568496Z","shell.execute_reply.started":"2021-10-24T05:35:38.961295Z","shell.execute_reply":"2021-10-24T05:35:40.567597Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model_type = 'Resnet_cbam'\nprint(model_type)\n\n# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'SVHN_%s_model.{epoch:03d}.h5' % model_type\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)\n\n# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor='val_acc',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]\nX_train, X_val, y_train, y_val\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n                        validation_data=(X_val, y_val),\n                        epochs=50, verbose=1, workers=4,\n                        callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T05:36:20.420492Z","iopub.execute_input":"2021-10-24T05:36:20.420786Z","iopub.status.idle":"2021-10-24T06:05:58.657342Z","shell.execute_reply.started":"2021-10-24T05:36:20.420755Z","shell.execute_reply":"2021-10-24T06:05:58.655949Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n# Score trained model.\nscores = model.evaluate(X_val, y_val, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:06:11.129688Z","iopub.execute_input":"2021-10-24T06:06:11.129979Z","iopub.status.idle":"2021-10-24T06:06:14.419286Z","shell.execute_reply.started":"2021-10-24T06:06:11.129947Z","shell.execute_reply":"2021-10-24T06:06:14.418572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Get predictions and apply inverse transformation to the labels\n\ny_pred = model.predict(X_train)\n\ny_pred = lb.inverse_transform(y_pred, lb.classes_)\ny_train = lb.inverse_transform(y_train, lb.classes_)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:09:30.064453Z","iopub.execute_input":"2021-10-24T06:09:30.064707Z","iopub.status.idle":"2021-10-24T06:09:53.096367Z","shell.execute_reply.started":"2021-10-24T06:09:30.064678Z","shell.execute_reply":"2021-10-24T06:09:53.095515Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Plot the confusion matrix\n\nmatrix = confusion_matrix(y_train, y_pred, labels=lb.classes_)\n\nfig, ax = plt.subplots(figsize=(14, 12))\nsns.heatmap(matrix, annot=True, cmap='Greens', fmt='d', ax=ax)\nplt.title('Confusion Matrix for training dataset')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:09:53.098177Z","iopub.execute_input":"2021-10-24T06:09:53.098467Z","iopub.status.idle":"2021-10-24T06:09:53.800469Z","shell.execute_reply.started":"2021-10-24T06:09:53.098432Z","shell.execute_reply":"2021-10-24T06:09:53.799760Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Ignore the errors in the plots\n\nnp.seterr(all='ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:10:21.561525Z","iopub.execute_input":"2021-10-24T06:10:21.561984Z","iopub.status.idle":"2021-10-24T06:10:21.574565Z","shell.execute_reply.started":"2021-10-24T06:10:21.561936Z","shell.execute_reply":"2021-10-24T06:10:21.573723Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Get convolutional layers\n\nlayers = [model.get_layer('conv2d_1'), \n          model.get_layer('conv2d_2'),\n          model.get_layer('conv2d_3'),\n          model.get_layer('conv2d_4'),\n          model.get_layer('conv2d_5'),\n          model.get_layer('conv2d_6')]","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:12:17.087685Z","iopub.execute_input":"2021-10-24T06:12:17.087964Z","iopub.status.idle":"2021-10-24T06:12:17.093790Z","shell.execute_reply.started":"2021-10-24T06:12:17.087928Z","shell.execute_reply":"2021-10-24T06:12:17.092938Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Define a model which gives the outputs of the layers\n\nlayer_outputs = [layer.output for layer in layers]\nactivation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:12:19.963721Z","iopub.execute_input":"2021-10-24T06:12:19.964259Z","iopub.status.idle":"2021-10-24T06:12:19.975447Z","shell.execute_reply.started":"2021-10-24T06:12:19.964223Z","shell.execute_reply":"2021-10-24T06:12:19.974571Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Create a list with the names of the layers\n\nlayer_names = []\nfor layer in layers:\n    layer_names.append(layer.name)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:12:21.784555Z","iopub.execute_input":"2021-10-24T06:12:21.785448Z","iopub.status.idle":"2021-10-24T06:12:21.789854Z","shell.execute_reply.started":"2021-10-24T06:12:21.785398Z","shell.execute_reply":"2021-10-24T06:12:21.789161Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Define a function which will plot the convolutional filters\n\ndef plot_convolutional_filters(img):\n    \n    img = np.expand_dims(img, axis=0)\n    activations = activation_model.predict(img)\n    images_per_row = 16\n    \n    for layer_name, layer_activation in zip(layer_names, activations): \n        n_features = layer_activation.shape[-1]\n        size = layer_activation.shape[1]\n        n_cols = n_features // images_per_row\n        display_grid = np.zeros((size * n_cols, images_per_row * size))\n        for col in range(n_cols): \n            for row in range(images_per_row):\n                channel_image = layer_activation[0,\n                                                 :, :,\n                                                 col * images_per_row + row]\n                channel_image -= channel_image.mean()\n                channel_image /= channel_image.std()\n                channel_image *= 64\n                channel_image += 128\n                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n                display_grid[col * size : (col + 1) * size,\n                             row * size : (row + 1) * size] = channel_image\n        scale = 1. / size\n        plt.figure(figsize=(scale * display_grid.shape[1],\n                            scale * display_grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='plasma')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:16:27.275971Z","iopub.execute_input":"2021-10-24T06:16:27.276755Z","iopub.status.idle":"2021-10-24T06:16:27.287373Z","shell.execute_reply.started":"2021-10-24T06:16:27.276716Z","shell.execute_reply":"2021-10-24T06:16:27.286468Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"img = X_train[42500]\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:16:27.620861Z","iopub.execute_input":"2021-10-24T06:16:27.621793Z","iopub.status.idle":"2021-10-24T06:16:27.806305Z","shell.execute_reply.started":"2021-10-24T06:16:27.621745Z","shell.execute_reply":"2021-10-24T06:16:27.805654Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"plot_convolutional_filters(img)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T06:16:27.918863Z","iopub.execute_input":"2021-10-24T06:16:27.919436Z","iopub.status.idle":"2021-10-24T06:16:29.022208Z","shell.execute_reply.started":"2021-10-24T06:16:27.919404Z","shell.execute_reply":"2021-10-24T06:16:29.021398Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}